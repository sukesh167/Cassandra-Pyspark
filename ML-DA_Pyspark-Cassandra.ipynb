{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled15.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEwcnJkaRyKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing cassandra into pyspark,\n",
        "import os\n",
        "import cassandra\n",
        "os.environ['PYSPARK_SUBMIT_ARGS'] = \\\n",
        "'--packages com.datastax.spark:\\\n",
        "spark-cassandra-connector_2.11:2.3.0 \\\n",
        "--conf spark.cassandra.connection.host=192.168.0.123,192.168.0.124 pyspark-shell'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLn8a1D2yjMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing all cassandra clusters in local system\n",
        "from cassandra.cluster import Cluster\n",
        "cluster = Cluster(['127.0.0.1'])\n",
        "session = cluster.connect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxWqf07xjrp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating a spark session\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext\n",
        "SpSession = SparkSession \\\n",
        "    .builder \\\n",
        "    .master(\"local[2]\") \\\n",
        "    .appName(\"iiitmk\") \\\n",
        "    .config(\"spark.executor.memory\", \"10g\") \\\n",
        "    .config(\"spark.cores.max\",\"24\") \\\n",
        "    .config(\"spark.sql.warehouse.dir\", \"/tmp/spark\")\\\n",
        "    .getOrCreate()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTU-qpGgLUqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing the spmrkts columnfamily(table) aa pandas dataframe for preprocessing\n",
        "import pandas as pd\n",
        "query = \"SELECT * from dba.sprmkts;\"\n",
        "df = pd.DataFrame(list(session.execute(query)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpbGAenpZHJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# customerid is not useful for predictions hence the column is dropped\n",
        "df.pop('idcustomer')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgbpeENXZMYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#gender column has values 1,2,M,F hence changing them to int values of just 1,2 (assuming M=1, F=2)\n",
        "inter=list(df['gender'])\n",
        "for i,j in enumerate(inter):\n",
        "  if(j=='M'):\n",
        "    inter[i]= 1\n",
        "  elif(j=='F'):\n",
        "    inter[i]= 2\n",
        "  elif(j=='1'):\n",
        "    inter[i]= 1\n",
        "  elif(j=='2'):\n",
        "    inter[i]= 2\n",
        "df['gender']=inter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAHYo1EyZgrS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#using pandas profilind=g for data analysis, visualisation\n",
        "import pandas_profiling as pp\n",
        "pp.ProfileReport(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7CNe9OEZiqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#removing excess 0 class values by random sampling because data is skewed\n",
        "from random import sample\n",
        "c1=[]\n",
        "c0=[]\n",
        "for i in df.index:\n",
        "if df.values[i][-1]==0:\n",
        "c0.append(i)\n",
        "elif df.values[i][-1]==1:\n",
        "c1.append(i)\n",
        "else:\n",
        "pass\n",
        "r0=sample(c0,197)\n",
        "r1=sample(c1,3)\n",
        "r=r1+r0\n",
        "df=df.drop(r)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucrVVpphZ1Yg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating pyspark dataframe(rdd) from pandas dataframe\n",
        "data = spark.createDataFrame(df)\n",
        "data.count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbck3pBoZ7iU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.describe('age','amount1','married_or_not').show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4qCVO4saCS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# correlation of features with label\n",
        "for i in data.columns:\n",
        "  if not( isinstance(data.select(i).take(1)[0][0], str)) :\n",
        "    print( \"Correlation to 'come' for \", i, data.stat.corr('come',i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JIjJtWAabGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating feature,label dataframe for model\n",
        "from pyspark.ml.linalg import Vectors\n",
        "def transformToLabeledPoint(row) :\n",
        "    lp = ( row[\"come\"], Vectors.dense([row[\"balance\"],row[\"gender\"],\\\n",
        "                                       row[\"education_level\"],row[\"married_or_not\"],\\\n",
        "                                       row[\"age\"],row[\"pay_month1\"],\\\n",
        "                                       row[\"pay_month2\"],row[\"pay_month3\"],\\\n",
        "                                       row[\"pay_month4\"],row[\"pay_month6\"],\\\n",
        "                                       row[\"pay_month7\"],row[\"amount1\"],\\\n",
        "                                       row[\"pay_amt1\"],row[\"pay_amt2\"],\\\n",
        "                                       row[\"pay_amt3\"],row[\"pay_amt4\"],\\\n",
        "                                       row[\"pay_amt5\"],row[\"pay_amt6\"]]))\n",
        "    return lp\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDDquW0laspa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.rdd.map(transformToLabeledPoint)\n",
        "data = SpSession.createDataFrame(data,[\"label\", \"features\"])\n",
        "data.select(\"label\",\"features\").show(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dk2VTSQawep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test-train split for SVM model\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "(training_data, test_data) = data.randomSplit([0.8, 0.2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XostXpI1a1Gi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SVM model\n",
        "SVMModel=LinearSVC()\n",
        "Model=SVMModel.fit(training_data)\n",
        "predictions = Model.transform(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qACXmS9Qa9om",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions.groupBy(\"label\",\"prediction\").count().show()\n",
        "Model.transform(training_data).groupBy(\"label\",\"prediction\").count().show()\n",
        "#confusion matrix"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}